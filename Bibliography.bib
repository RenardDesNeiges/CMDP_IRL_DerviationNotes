@misc{EE618,
  title = {Theory and Methods for Reinforcement Learning (EE-618)},
  author = {Volkan Cevher and He Niao},
  Institution = {EPFL},
  Howpublished = {Course Slides},
  Year = {2022},
}

@article{Schlaginhaufen2023,
  author  = {Andreas Schlaginhaufen},
  title   = {Identifiability and generalizability in constrained inverse reinforcement learning},
  journal = {preprint},
  year    = {2023},
}

@article{Zeng2022,
  author  = {Siliang Zeng and Chenliang Li and Alfredo Garcia and Mingyi Hong},
  title   = {Maximum-Likelihood Inverse Reinforcement Learning with Finite-Time Guarantees},
  journal = {arxiv},
  year    = {2022},
}

@article{Mokhtari2019,
  author  = {Aryan Mokhtari and Asuman Ozdaglar and Sarath Pattathil},
  title   = {A Unified Analysis of Extra-gradient and Optimistic Gradient Methods for Saddle Point Problems: Proximal Point Approach},
  journal = {Proceedings of Machine Learning Research},
  year    = {2019},
}

@article{Agarwal2020,
  author  = {Alekh Agarwal and Sham M. Kakade and Jason D. Lee and Gaurav Mahajan},
  title   = {On the Theory of Policy Gradient Methods: Optimality, Approximation, and Distribution Shift},
  journal = {Proceedings of Machine Learning Research},
  year    = {2020},
}

@article{Yuan2022,
  author  = {Rui Yuan and Robert M Gower and Alessandro Lazaric},
  title   = {A general sample complexity analysis of vanilla policy gradient},
  journal = {International Conference on Artificial Intelligence and Statistics},
  year    = {2022},
}

@article{Yuan2022,
  author  = {Rui Yuan and Robert M Gower and Alessandro Lazaric},
  title   = {A general sample complexity analysis of vanilla policy gradient},
  journal = {International Conference on Artificial Intelligence and Statistics},
  year    = {2022},
}

@article{Bubeck2019,
  author  = {SÃ©bastien Bubeck},
  title   = {The 5 miracles of miror descent},
  Howpublished = {Video Lectures},
  Institution = {Microsoft Research},
  Year = {2019},
}


@article{nemirovski_prox-method_2004,
	title = {Prox-{Method} with {Rate} of {Convergence} \textit{{O}} (1/ \textit{t} ) for {Variational} {Inequalities} with {Lipschitz} {Continuous} {Monotone} {Operators} and {Smooth} {Convex}-{Concave} {Saddle} {Point} {Problems}},
	volume = {15},
	issn = {1052-6234, 1095-7189},
	url = {http://epubs.siam.org/doi/10.1137/S1052623403425629},
	doi = {10.1137/S1052623403425629},
	language = {en},
	number = {1},
	urldate = {2023-03-17},
	journal = {SIAM Journal on Optimization},
	author = {Nemirovski, Arkadi},
	month = jan,
	year = {2004},
	pages = {229--251},
}



@article{sion_general_1958,
	title = {On general minimax theorems},
	volume = {8},
	issn = {0030-8730, 0030-8730},
	url = {http://msp.org/pjm/1958/8-1/p14.xhtml},
	doi = {10.2140/pjm.1958.8.171},
	language = {en},
	number = {1},
	urldate = {2023-03-20},
	journal = {Pacific Journal of Mathematics},
	author = {Sion, Maurice},
	month = mar,
	year = {1958},
	pages = {171--176},
}

@inproceedings{
gorbunov2022lastiterate,
title={Last-Iterate Convergence of Optimistic Gradient Method for Monotone Variational Inequalities},
author={Eduard Gorbunov and Adrien Taylor and Gauthier Gidel},
booktitle={Advances in Neural Information Processing Systems},
editor={Alice H. Oh and Alekh Agarwal and Danielle Belgrave and Kyunghyun Cho},
year={2022},
}
@inproceedings{Cai2022TightLC,
title={Tight Last-Iterate Convergence of the Extragradient and the Optimistic Gradient Descent-Ascent Algorithm for Constrained Monotone Variational Inequalities},
author={Yang Cai and Argyris Oikonomou and Weiqiang Zheng},
booktitle={Advances in Neural Information Processing Systems},
year={2022}
}

@article{MokhtariOGEG2020,
author = {Mokhtari Aryan and Ozdaglar Asuman E. and Pattathil Sarath},
title = {Convergence Rate of O(1/k) for Optimistic Gradient and Extragradient Methods in Smooth Convex-Concave Saddle Point Problems},
journal = {SIAM Journal on Optimization},
year = {2020},
doi = {10.1137/19M127375X},
}


